---
layout: post
title:  "SinGAN : Learning a Generative Model from a Single Natural Image"
date:   2019-11-26
excerpt: "SinGAN paper review"
tag:
- Deeplearning
- GAN 
- GenerativeAdversarialNetwork
- SinGAN
- SingleNaturalImage
- ICCV2019
- BestPaper
comments: true
---

[[paper]](https://arxiv.org/abs/1905.01164)

[[code]](https://github.com/tamarott/SinGAN)

SPatially-Adaptive-DEnormalization
==================================

## 1. Introduction
<img src="/images/SinGAN/1.png">

** i. Problem Define **

- Unconditional Image Generate 를 이용해 High Resolution을 생성하는 일은 굉장히 큰 발전을 이루어 오고 있다.
- 그러나 여러 클래스가 한꺼번에 들어와 있는 경우는 여전히 도전대상이다. (e.g : Image Net 등)
- 이런 사진의 경우 input signal( Guided를 말하는건가?)이나 다른 task에 얽매여 생성 할 수 있다.



** ii. Contribution **

<img src="/images/SinGAN/2.png">

- Single Image만으로도 학습이 가능함을 강조
- Bidirectional patch를 사용하여 조작 된(Manipulated) 이미지의 패치가 원래의 패치와 동일하도록 적용
- Single Image로 다양한 task를 진행한다 (Paint to Image, Editing, Harmonization, S-R, Animation)
- 단 하나의 모델로 (물론 트레이닝은 다양하게) 이 모든 task가 가능함


## 2. Related works

** i. Single Image Deep Models

	<img src="/images/SinGAN/3.png">
	이 그림에서 처럼 textual를 패턴처럼 사용하지 않는다는 것을 보여주는 figure

- 특별한 task에 맞게 "overfit"되지 않은 순수한 generative model이다 (S-R이나 texture에 맞게 생성하는 RW을 예로듬 )
- 그리고 Unconditional GAN들은 대부분 context나 textual에 의존하여 이미지를 생성했지만 our model은 그렇지 않음 (Fig.3)

** ii. Generative models for image manipulation

- 주 도메인이라 생략함

## 3. Method

    
